{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Using cached Scrapy-2.5.0-py2.py3-none-any.whl (254 kB)\n",
      "Collecting Twisted[http2]>=17.9.0\n",
      "  Using cached Twisted-21.2.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting parsel>=1.5.0\n",
      "  Using cached parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Using cached itemadapter-0.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in c:\\users\\amd\\anaconda3\\lib\\site-packages (from scrapy) (4.6.1)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from scrapy) (3.1.1)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from scrapy) (19.1.0)\n",
      "Collecting h2<4.0,>=3.0\n",
      "Note: you may need to restart the kernel to use updated packages.  Using cached h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Collecting PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\"\n",
      "  Downloading PyDispatcher-2.0.5.tar.gz (34 kB)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Using cached w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Using cached cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Using cached queuelib-1.6.1-py2.py3-none-any.whl (12 kB)\n",
      "Collecting service-identity>=16.0.0\n",
      "  Using cached service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting protego>=0.1.15\n",
      "\n",
      "  Using cached Protego-0.1.16.tar.gz (3.2 MB)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from scrapy) (5.1.2)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Using cached itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting constantly>=15.1\n",
      "  Using cached constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting incremental>=16.10.1\n",
      "  Using cached incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (20.3.0)\n",
      "Collecting Automat>=0.8.0\n",
      "  Using cached Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting twisted-iocpsupport~=1.0.0; platform_system == \"Windows\"\n",
      "  Using cached twisted_iocpsupport-1.0.1-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Collecting priority<2.0,>=1.1.0; extra == \"http2\"\n",
      "  Using cached priority-1.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.14.3)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Using cached hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Using cached hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\amd\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amd\\anaconda3\\lib\\site-packages (from zope.interface>=4.1.3->scrapy) (50.3.1.post20201107)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\amd\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted[http2]>=17.9.0->scrapy) (2.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\amd\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy) (2.20)\n",
      "Building wheels for collected packages: PyDispatcher, protego\n",
      "  Building wheel for PyDispatcher (setup.py): started\n",
      "  Building wheel for PyDispatcher (setup.py): finished with status 'done'\n",
      "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-py3-none-any.whl size=12552 sha256=79b38324b637be48845846f22ed6169fbcbb6dd63d212134f298de77978f8dfb\n",
      "  Stored in directory: c:\\users\\amd\\appdata\\local\\pip\\cache\\wheels\\d1\\d7\\61\\11b5b370ee487d38b5408ecb7e0257db9107fa622412cbe2ff\n",
      "  Building wheel for protego (setup.py): started\n",
      "  Building wheel for protego (setup.py): finished with status 'done'\n",
      "  Created wheel for protego: filename=Protego-0.1.16-py3-none-any.whl size=7770 sha256=e26c4f608608d68d7835f69feeb0e713c2c71134c8eb7bcff6b21081038df240\n",
      "  Stored in directory: c:\\users\\amd\\appdata\\local\\pip\\cache\\wheels\\91\\64\\36\\bd0d11306cb22a78c7f53d603c7eb74ebb6c211703bc40b686\n",
      "Successfully built PyDispatcher protego\n",
      "Installing collected packages: constantly, hyperlink, incremental, Automat, twisted-iocpsupport, priority, hpack, hyperframe, h2, Twisted, w3lib, cssselect, parsel, itemadapter, PyDispatcher, queuelib, service-identity, protego, jmespath, itemloaders, scrapy\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-21.2.0 constantly-15.1.0 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.3.0 itemloaders-1.0.4 jmespath-0.10.0 parsel-1.6.0 priority-1.3.0 protego-0.1.16 queuelib-1.6.1 scrapy-2.5.0 service-identity-21.1.0 twisted-iocpsupport-1.0.1 w3lib-1.22.0\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://en.wikipedia.org/wiki/Naruto',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall(),\n",
    "            }\n",
    "\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
