{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\AMD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\AMD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saint_Patrick = '''\n",
    " Saint Patrick (Latin: Patricius; Irish: Pádraig [ˈpˠaːd̪ˠɾˠəɟ]; Welsh: Padrig) was a fifth-century Romano-British Christian missionary and bishop in Ireland. Known as the \"Apostle of Ireland\", he is the primary patron saint of Ireland, the other patron saints being Brigit of Kildare and Columba. Patrick was never formally canonised,[2] having lived prior to the current laws of the Catholic Church in these matters. Nevertheless, he is venerated as a Saint in the Catholic Church and in the Eastern Orthodox Church, where he is regarded as equal-to-the-apostles and Enlightener of Ireland. He is also regarded as a Saint within the framework of their respective doctrine by the Anglican Communion and the Lutheran Churches.[3]\n",
    "\n",
    "The dates of Patrick's life cannot be fixed with certainty, but there is general agreement that he was active as a missionary in Ireland during the fifth century. A recent biography[4] on Patrick shows, a late fourth-century date for the saint is not impossible.[5] Early medieval tradition credits him with being the first bishop of Armagh and Primate of Ireland, and regards him as the founder of Christianity in Ireland, converting a society practising a form of Celtic polytheism. He has been generally so regarded ever since, despite evidence of some earlier Christian presence in Ireland.\n",
    "\n",
    "According to the autobiographical Confessio of Patrick, when he was about sixteen, he was captured by Irish pirates from his home in Britain and taken as a slave to Ireland, looking after animals; he lived there for six years before escaping and returning to his family. After becoming a cleric, he returned to northern and western Ireland. In later life, he served as a bishop, but little is known about the places where he worked. By the seventh century, he had already come to be revered as the patron saint of Ireland.\n",
    "\n",
    "Saint Patrick's Day is observed on 17 March, the supposed date of his death. It is celebrated inside and outside Ireland as a religious and cultural holiday. In the dioceses of Ireland, it is both a solemnity and a holy day of obligation; it is also a celebration of Ireland itself.\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saint',\n",
       " 'Patrick',\n",
       " '(',\n",
       " 'Latin',\n",
       " ':',\n",
       " 'Patricius',\n",
       " ';',\n",
       " 'Irish',\n",
       " ':',\n",
       " 'Pádraig',\n",
       " '[',\n",
       " 'ˈpˠaːd̪ˠɾˠəɟ',\n",
       " ']',\n",
       " ';',\n",
       " 'Welsh',\n",
       " ':',\n",
       " 'Padrig',\n",
       " ')',\n",
       " 'was',\n",
       " 'a',\n",
       " 'fifth-century',\n",
       " 'Romano-British',\n",
       " 'Christian',\n",
       " 'missionary',\n",
       " 'and',\n",
       " 'bishop',\n",
       " 'in',\n",
       " 'Ireland',\n",
       " '.',\n",
       " 'Known',\n",
       " 'as',\n",
       " 'the',\n",
       " '``',\n",
       " 'Apostle',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " \"''\",\n",
       " ',',\n",
       " 'he',\n",
       " 'is',\n",
       " 'the',\n",
       " 'primary',\n",
       " 'patron',\n",
       " 'saint',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " ',',\n",
       " 'the',\n",
       " 'other',\n",
       " 'patron',\n",
       " 'saints',\n",
       " 'being',\n",
       " 'Brigit',\n",
       " 'of',\n",
       " 'Kildare',\n",
       " 'and',\n",
       " 'Columba',\n",
       " '.',\n",
       " 'Patrick',\n",
       " 'was',\n",
       " 'never',\n",
       " 'formally',\n",
       " 'canonised',\n",
       " ',',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'having',\n",
       " 'lived',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'the',\n",
       " 'current',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Catholic',\n",
       " 'Church',\n",
       " 'in',\n",
       " 'these',\n",
       " 'matters',\n",
       " '.',\n",
       " 'Nevertheless',\n",
       " ',',\n",
       " 'he',\n",
       " 'is',\n",
       " 'venerated',\n",
       " 'as',\n",
       " 'a',\n",
       " 'Saint',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Catholic',\n",
       " 'Church',\n",
       " 'and',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Eastern',\n",
       " 'Orthodox',\n",
       " 'Church',\n",
       " ',',\n",
       " 'where',\n",
       " 'he',\n",
       " 'is',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'equal-to-the-apostles',\n",
       " 'and',\n",
       " 'Enlightener',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " '.',\n",
       " 'He',\n",
       " 'is',\n",
       " 'also',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'a',\n",
       " 'Saint',\n",
       " 'within',\n",
       " 'the',\n",
       " 'framework',\n",
       " 'of',\n",
       " 'their',\n",
       " 'respective',\n",
       " 'doctrine',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Anglican',\n",
       " 'Communion',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Lutheran',\n",
       " 'Churches',\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'The',\n",
       " 'dates',\n",
       " 'of',\n",
       " 'Patrick',\n",
       " \"'s\",\n",
       " 'life',\n",
       " 'can',\n",
       " 'not',\n",
       " 'be',\n",
       " 'fixed',\n",
       " 'with',\n",
       " 'certainty',\n",
       " ',',\n",
       " 'but',\n",
       " 'there',\n",
       " 'is',\n",
       " 'general',\n",
       " 'agreement',\n",
       " 'that',\n",
       " 'he',\n",
       " 'was',\n",
       " 'active',\n",
       " 'as',\n",
       " 'a',\n",
       " 'missionary',\n",
       " 'in',\n",
       " 'Ireland',\n",
       " 'during',\n",
       " 'the',\n",
       " 'fifth',\n",
       " 'century',\n",
       " '.',\n",
       " 'A',\n",
       " 'recent',\n",
       " 'biography',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'on',\n",
       " 'Patrick',\n",
       " 'shows',\n",
       " ',',\n",
       " 'a',\n",
       " 'late',\n",
       " 'fourth-century',\n",
       " 'date',\n",
       " 'for',\n",
       " 'the',\n",
       " 'saint',\n",
       " 'is',\n",
       " 'not',\n",
       " 'impossible',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'Early',\n",
       " 'medieval',\n",
       " 'tradition',\n",
       " 'credits',\n",
       " 'him',\n",
       " 'with',\n",
       " 'being',\n",
       " 'the',\n",
       " 'first',\n",
       " 'bishop',\n",
       " 'of',\n",
       " 'Armagh',\n",
       " 'and',\n",
       " 'Primate',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " ',',\n",
       " 'and',\n",
       " 'regards',\n",
       " 'him',\n",
       " 'as',\n",
       " 'the',\n",
       " 'founder',\n",
       " 'of',\n",
       " 'Christianity',\n",
       " 'in',\n",
       " 'Ireland',\n",
       " ',',\n",
       " 'converting',\n",
       " 'a',\n",
       " 'society',\n",
       " 'practising',\n",
       " 'a',\n",
       " 'form',\n",
       " 'of',\n",
       " 'Celtic',\n",
       " 'polytheism',\n",
       " '.',\n",
       " 'He',\n",
       " 'has',\n",
       " 'been',\n",
       " 'generally',\n",
       " 'so',\n",
       " 'regarded',\n",
       " 'ever',\n",
       " 'since',\n",
       " ',',\n",
       " 'despite',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'some',\n",
       " 'earlier',\n",
       " 'Christian',\n",
       " 'presence',\n",
       " 'in',\n",
       " 'Ireland',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'the',\n",
       " 'autobiographical',\n",
       " 'Confessio',\n",
       " 'of',\n",
       " 'Patrick',\n",
       " ',',\n",
       " 'when',\n",
       " 'he',\n",
       " 'was',\n",
       " 'about',\n",
       " 'sixteen',\n",
       " ',',\n",
       " 'he',\n",
       " 'was',\n",
       " 'captured',\n",
       " 'by',\n",
       " 'Irish',\n",
       " 'pirates',\n",
       " 'from',\n",
       " 'his',\n",
       " 'home',\n",
       " 'in',\n",
       " 'Britain',\n",
       " 'and',\n",
       " 'taken',\n",
       " 'as',\n",
       " 'a',\n",
       " 'slave',\n",
       " 'to',\n",
       " 'Ireland',\n",
       " ',',\n",
       " 'looking',\n",
       " 'after',\n",
       " 'animals',\n",
       " ';',\n",
       " 'he',\n",
       " 'lived',\n",
       " 'there',\n",
       " 'for',\n",
       " 'six',\n",
       " 'years',\n",
       " 'before',\n",
       " 'escaping',\n",
       " 'and',\n",
       " 'returning',\n",
       " 'to',\n",
       " 'his',\n",
       " 'family',\n",
       " '.',\n",
       " 'After',\n",
       " 'becoming',\n",
       " 'a',\n",
       " 'cleric',\n",
       " ',',\n",
       " 'he',\n",
       " 'returned',\n",
       " 'to',\n",
       " 'northern',\n",
       " 'and',\n",
       " 'western',\n",
       " 'Ireland',\n",
       " '.',\n",
       " 'In',\n",
       " 'later',\n",
       " 'life',\n",
       " ',',\n",
       " 'he',\n",
       " 'served',\n",
       " 'as',\n",
       " 'a',\n",
       " 'bishop',\n",
       " ',',\n",
       " 'but',\n",
       " 'little',\n",
       " 'is',\n",
       " 'known',\n",
       " 'about',\n",
       " 'the',\n",
       " 'places',\n",
       " 'where',\n",
       " 'he',\n",
       " 'worked',\n",
       " '.',\n",
       " 'By',\n",
       " 'the',\n",
       " 'seventh',\n",
       " 'century',\n",
       " ',',\n",
       " 'he',\n",
       " 'had',\n",
       " 'already',\n",
       " 'come',\n",
       " 'to',\n",
       " 'be',\n",
       " 'revered',\n",
       " 'as',\n",
       " 'the',\n",
       " 'patron',\n",
       " 'saint',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " '.',\n",
       " 'Saint',\n",
       " 'Patrick',\n",
       " \"'s\",\n",
       " 'Day',\n",
       " 'is',\n",
       " 'observed',\n",
       " 'on',\n",
       " '17',\n",
       " 'March',\n",
       " ',',\n",
       " 'the',\n",
       " 'supposed',\n",
       " 'date',\n",
       " 'of',\n",
       " 'his',\n",
       " 'death',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'celebrated',\n",
       " 'inside',\n",
       " 'and',\n",
       " 'outside',\n",
       " 'Ireland',\n",
       " 'as',\n",
       " 'a',\n",
       " 'religious',\n",
       " 'and',\n",
       " 'cultural',\n",
       " 'holiday',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'dioceses',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'both',\n",
       " 'a',\n",
       " 'solemnity',\n",
       " 'and',\n",
       " 'a',\n",
       " 'holy',\n",
       " 'day',\n",
       " 'of',\n",
       " 'obligation',\n",
       " ';',\n",
       " 'it',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'celebration',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " 'itself',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Saint_Patrick_tokens = word_tokenize(Saint_Patrick)\n",
    "Saint_Patrick_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 21, ',': 19, 'of': 18, '.': 16, 'a': 15, 'ireland': 14, 'and': 13, 'he': 13, 'is': 11, 'in': 10, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in Saint_Patrick_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 21),\n",
       " (',', 19),\n",
       " ('of', 18),\n",
       " ('.', 16),\n",
       " ('a', 15),\n",
       " ('ireland', 14),\n",
       " ('and', 13),\n",
       " ('he', 13),\n",
       " ('is', 11),\n",
       " ('in', 10)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_most = fdist.most_common(10)\n",
    "fdist_most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "Saint_Patrick_blank = blankline_tokenize(Saint_Patrick)\n",
    "len(Saint_Patrick_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams, bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = '''\n",
    "Varieties of the color green may differ in hue, chroma (also called saturation or intensity) or lightness \n",
    "(or value, tone, or brightness), or in two or three of these qualities. Variations in value are also called tints and shades, \n",
    "a tint being a green or other hue mixed with white, a shade being mixed with black. A large selection of these various colors is\n",
    "shown below.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Varieties',\n",
       " 'of',\n",
       " 'the',\n",
       " 'color',\n",
       " 'green',\n",
       " 'may',\n",
       " 'differ',\n",
       " 'in',\n",
       " 'hue',\n",
       " ',',\n",
       " 'chroma',\n",
       " '(',\n",
       " 'also',\n",
       " 'called',\n",
       " 'saturation',\n",
       " 'or',\n",
       " 'intensity',\n",
       " ')',\n",
       " 'or',\n",
       " 'lightness',\n",
       " '(',\n",
       " 'or',\n",
       " 'value',\n",
       " ',',\n",
       " 'tone',\n",
       " ',',\n",
       " 'or',\n",
       " 'brightness',\n",
       " ')',\n",
       " ',',\n",
       " 'or',\n",
       " 'in',\n",
       " 'two',\n",
       " 'or',\n",
       " 'three',\n",
       " 'of',\n",
       " 'these',\n",
       " 'qualities',\n",
       " '.',\n",
       " 'Variations',\n",
       " 'in',\n",
       " 'value',\n",
       " 'are',\n",
       " 'also',\n",
       " 'called',\n",
       " 'tints',\n",
       " 'and',\n",
       " 'shades',\n",
       " ',',\n",
       " 'a',\n",
       " 'tint',\n",
       " 'being',\n",
       " 'a',\n",
       " 'green',\n",
       " 'or',\n",
       " 'other',\n",
       " 'hue',\n",
       " 'mixed',\n",
       " 'with',\n",
       " 'white',\n",
       " ',',\n",
       " 'a',\n",
       " 'shade',\n",
       " 'being',\n",
       " 'mixed',\n",
       " 'with',\n",
       " 'black',\n",
       " '.',\n",
       " 'A',\n",
       " 'large',\n",
       " 'selection',\n",
       " 'of',\n",
       " 'these',\n",
       " 'various',\n",
       " 'colors',\n",
       " 'is',\n",
       " 'shown',\n",
       " 'below',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_token = word_tokenize(green)\n",
    "green_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(green_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Varieties', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'color'),\n",
       " ('color', 'green'),\n",
       " ('green', 'may'),\n",
       " ('may', 'differ'),\n",
       " ('differ', 'in'),\n",
       " ('in', 'hue'),\n",
       " ('hue', ','),\n",
       " (',', 'chroma'),\n",
       " ('chroma', '('),\n",
       " ('(', 'also'),\n",
       " ('also', 'called'),\n",
       " ('called', 'saturation'),\n",
       " ('saturation', 'or'),\n",
       " ('or', 'intensity'),\n",
       " ('intensity', ')'),\n",
       " (')', 'or'),\n",
       " ('or', 'lightness'),\n",
       " ('lightness', '('),\n",
       " ('(', 'or'),\n",
       " ('or', 'value'),\n",
       " ('value', ','),\n",
       " (',', 'tone'),\n",
       " ('tone', ','),\n",
       " (',', 'or'),\n",
       " ('or', 'brightness'),\n",
       " ('brightness', ')'),\n",
       " (')', ','),\n",
       " (',', 'or'),\n",
       " ('or', 'in'),\n",
       " ('in', 'two'),\n",
       " ('two', 'or'),\n",
       " ('or', 'three'),\n",
       " ('three', 'of'),\n",
       " ('of', 'these'),\n",
       " ('these', 'qualities'),\n",
       " ('qualities', '.'),\n",
       " ('.', 'Variations'),\n",
       " ('Variations', 'in'),\n",
       " ('in', 'value'),\n",
       " ('value', 'are'),\n",
       " ('are', 'also'),\n",
       " ('also', 'called'),\n",
       " ('called', 'tints'),\n",
       " ('tints', 'and'),\n",
       " ('and', 'shades'),\n",
       " ('shades', ','),\n",
       " (',', 'a'),\n",
       " ('a', 'tint'),\n",
       " ('tint', 'being'),\n",
       " ('being', 'a'),\n",
       " ('a', 'green'),\n",
       " ('green', 'or'),\n",
       " ('or', 'other'),\n",
       " ('other', 'hue'),\n",
       " ('hue', 'mixed'),\n",
       " ('mixed', 'with'),\n",
       " ('with', 'white'),\n",
       " ('white', ','),\n",
       " (',', 'a'),\n",
       " ('a', 'shade'),\n",
       " ('shade', 'being'),\n",
       " ('being', 'mixed'),\n",
       " ('mixed', 'with'),\n",
       " ('with', 'black'),\n",
       " ('black', '.'),\n",
       " ('.', 'A'),\n",
       " ('A', 'large'),\n",
       " ('large', 'selection'),\n",
       " ('selection', 'of'),\n",
       " ('of', 'these'),\n",
       " ('these', 'various'),\n",
       " ('various', 'colors'),\n",
       " ('colors', 'is'),\n",
       " ('is', 'shown'),\n",
       " ('shown', 'below'),\n",
       " ('below', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_bigrams = list(bigrams(green_token))\n",
    "green_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Varieties', 'of', 'the'),\n",
       " ('of', 'the', 'color'),\n",
       " ('the', 'color', 'green'),\n",
       " ('color', 'green', 'may'),\n",
       " ('green', 'may', 'differ'),\n",
       " ('may', 'differ', 'in'),\n",
       " ('differ', 'in', 'hue'),\n",
       " ('in', 'hue', ','),\n",
       " ('hue', ',', 'chroma'),\n",
       " (',', 'chroma', '('),\n",
       " ('chroma', '(', 'also'),\n",
       " ('(', 'also', 'called'),\n",
       " ('also', 'called', 'saturation'),\n",
       " ('called', 'saturation', 'or'),\n",
       " ('saturation', 'or', 'intensity'),\n",
       " ('or', 'intensity', ')'),\n",
       " ('intensity', ')', 'or'),\n",
       " (')', 'or', 'lightness'),\n",
       " ('or', 'lightness', '('),\n",
       " ('lightness', '(', 'or'),\n",
       " ('(', 'or', 'value'),\n",
       " ('or', 'value', ','),\n",
       " ('value', ',', 'tone'),\n",
       " (',', 'tone', ','),\n",
       " ('tone', ',', 'or'),\n",
       " (',', 'or', 'brightness'),\n",
       " ('or', 'brightness', ')'),\n",
       " ('brightness', ')', ','),\n",
       " (')', ',', 'or'),\n",
       " (',', 'or', 'in'),\n",
       " ('or', 'in', 'two'),\n",
       " ('in', 'two', 'or'),\n",
       " ('two', 'or', 'three'),\n",
       " ('or', 'three', 'of'),\n",
       " ('three', 'of', 'these'),\n",
       " ('of', 'these', 'qualities'),\n",
       " ('these', 'qualities', '.'),\n",
       " ('qualities', '.', 'Variations'),\n",
       " ('.', 'Variations', 'in'),\n",
       " ('Variations', 'in', 'value'),\n",
       " ('in', 'value', 'are'),\n",
       " ('value', 'are', 'also'),\n",
       " ('are', 'also', 'called'),\n",
       " ('also', 'called', 'tints'),\n",
       " ('called', 'tints', 'and'),\n",
       " ('tints', 'and', 'shades'),\n",
       " ('and', 'shades', ','),\n",
       " ('shades', ',', 'a'),\n",
       " (',', 'a', 'tint'),\n",
       " ('a', 'tint', 'being'),\n",
       " ('tint', 'being', 'a'),\n",
       " ('being', 'a', 'green'),\n",
       " ('a', 'green', 'or'),\n",
       " ('green', 'or', 'other'),\n",
       " ('or', 'other', 'hue'),\n",
       " ('other', 'hue', 'mixed'),\n",
       " ('hue', 'mixed', 'with'),\n",
       " ('mixed', 'with', 'white'),\n",
       " ('with', 'white', ','),\n",
       " ('white', ',', 'a'),\n",
       " (',', 'a', 'shade'),\n",
       " ('a', 'shade', 'being'),\n",
       " ('shade', 'being', 'mixed'),\n",
       " ('being', 'mixed', 'with'),\n",
       " ('mixed', 'with', 'black'),\n",
       " ('with', 'black', '.'),\n",
       " ('black', '.', 'A'),\n",
       " ('.', 'A', 'large'),\n",
       " ('A', 'large', 'selection'),\n",
       " ('large', 'selection', 'of'),\n",
       " ('selection', 'of', 'these'),\n",
       " ('of', 'these', 'various'),\n",
       " ('these', 'various', 'colors'),\n",
       " ('various', 'colors', 'is'),\n",
       " ('colors', 'is', 'shown'),\n",
       " ('is', 'shown', 'below'),\n",
       " ('shown', 'below', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_trigrams = list(trigrams(green_token))\n",
    "green_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Varieties', 'of', 'the', 'color', 'green'),\n",
       " ('of', 'the', 'color', 'green', 'may'),\n",
       " ('the', 'color', 'green', 'may', 'differ'),\n",
       " ('color', 'green', 'may', 'differ', 'in'),\n",
       " ('green', 'may', 'differ', 'in', 'hue'),\n",
       " ('may', 'differ', 'in', 'hue', ','),\n",
       " ('differ', 'in', 'hue', ',', 'chroma'),\n",
       " ('in', 'hue', ',', 'chroma', '('),\n",
       " ('hue', ',', 'chroma', '(', 'also'),\n",
       " (',', 'chroma', '(', 'also', 'called'),\n",
       " ('chroma', '(', 'also', 'called', 'saturation'),\n",
       " ('(', 'also', 'called', 'saturation', 'or'),\n",
       " ('also', 'called', 'saturation', 'or', 'intensity'),\n",
       " ('called', 'saturation', 'or', 'intensity', ')'),\n",
       " ('saturation', 'or', 'intensity', ')', 'or'),\n",
       " ('or', 'intensity', ')', 'or', 'lightness'),\n",
       " ('intensity', ')', 'or', 'lightness', '('),\n",
       " (')', 'or', 'lightness', '(', 'or'),\n",
       " ('or', 'lightness', '(', 'or', 'value'),\n",
       " ('lightness', '(', 'or', 'value', ','),\n",
       " ('(', 'or', 'value', ',', 'tone'),\n",
       " ('or', 'value', ',', 'tone', ','),\n",
       " ('value', ',', 'tone', ',', 'or'),\n",
       " (',', 'tone', ',', 'or', 'brightness'),\n",
       " ('tone', ',', 'or', 'brightness', ')'),\n",
       " (',', 'or', 'brightness', ')', ','),\n",
       " ('or', 'brightness', ')', ',', 'or'),\n",
       " ('brightness', ')', ',', 'or', 'in'),\n",
       " (')', ',', 'or', 'in', 'two'),\n",
       " (',', 'or', 'in', 'two', 'or'),\n",
       " ('or', 'in', 'two', 'or', 'three'),\n",
       " ('in', 'two', 'or', 'three', 'of'),\n",
       " ('two', 'or', 'three', 'of', 'these'),\n",
       " ('or', 'three', 'of', 'these', 'qualities'),\n",
       " ('three', 'of', 'these', 'qualities', '.'),\n",
       " ('of', 'these', 'qualities', '.', 'Variations'),\n",
       " ('these', 'qualities', '.', 'Variations', 'in'),\n",
       " ('qualities', '.', 'Variations', 'in', 'value'),\n",
       " ('.', 'Variations', 'in', 'value', 'are'),\n",
       " ('Variations', 'in', 'value', 'are', 'also'),\n",
       " ('in', 'value', 'are', 'also', 'called'),\n",
       " ('value', 'are', 'also', 'called', 'tints'),\n",
       " ('are', 'also', 'called', 'tints', 'and'),\n",
       " ('also', 'called', 'tints', 'and', 'shades'),\n",
       " ('called', 'tints', 'and', 'shades', ','),\n",
       " ('tints', 'and', 'shades', ',', 'a'),\n",
       " ('and', 'shades', ',', 'a', 'tint'),\n",
       " ('shades', ',', 'a', 'tint', 'being'),\n",
       " (',', 'a', 'tint', 'being', 'a'),\n",
       " ('a', 'tint', 'being', 'a', 'green'),\n",
       " ('tint', 'being', 'a', 'green', 'or'),\n",
       " ('being', 'a', 'green', 'or', 'other'),\n",
       " ('a', 'green', 'or', 'other', 'hue'),\n",
       " ('green', 'or', 'other', 'hue', 'mixed'),\n",
       " ('or', 'other', 'hue', 'mixed', 'with'),\n",
       " ('other', 'hue', 'mixed', 'with', 'white'),\n",
       " ('hue', 'mixed', 'with', 'white', ','),\n",
       " ('mixed', 'with', 'white', ',', 'a'),\n",
       " ('with', 'white', ',', 'a', 'shade'),\n",
       " ('white', ',', 'a', 'shade', 'being'),\n",
       " (',', 'a', 'shade', 'being', 'mixed'),\n",
       " ('a', 'shade', 'being', 'mixed', 'with'),\n",
       " ('shade', 'being', 'mixed', 'with', 'black'),\n",
       " ('being', 'mixed', 'with', 'black', '.'),\n",
       " ('mixed', 'with', 'black', '.', 'A'),\n",
       " ('with', 'black', '.', 'A', 'large'),\n",
       " ('black', '.', 'A', 'large', 'selection'),\n",
       " ('.', 'A', 'large', 'selection', 'of'),\n",
       " ('A', 'large', 'selection', 'of', 'these'),\n",
       " ('large', 'selection', 'of', 'these', 'various'),\n",
       " ('selection', 'of', 'these', 'various', 'colors'),\n",
       " ('of', 'these', 'various', 'colors', 'is'),\n",
       " ('these', 'various', 'colors', 'is', 'shown'),\n",
       " ('various', 'colors', 'is', 'shown', 'below'),\n",
       " ('colors', 'is', 'shown', 'below', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_ngrams = list(ngrams(green_token,5))\n",
    "green_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = re.compile(r'[-.,!;:()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punct = []\n",
    "for words in green_token:\n",
    "    words = punct.sub(\"\",words)\n",
    "    if len(words)>0:\n",
    "        post_punct.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Varieties',\n",
       " 'of',\n",
       " 'the',\n",
       " 'color',\n",
       " 'green',\n",
       " 'may',\n",
       " 'differ',\n",
       " 'in',\n",
       " 'hue',\n",
       " 'chroma',\n",
       " 'also',\n",
       " 'called',\n",
       " 'saturation',\n",
       " 'or',\n",
       " 'intensity',\n",
       " 'or',\n",
       " 'lightness',\n",
       " 'or',\n",
       " 'value',\n",
       " 'tone',\n",
       " 'or',\n",
       " 'brightness',\n",
       " 'or',\n",
       " 'in',\n",
       " 'two',\n",
       " 'or',\n",
       " 'three',\n",
       " 'of',\n",
       " 'these',\n",
       " 'qualities',\n",
       " 'Variations',\n",
       " 'in',\n",
       " 'value',\n",
       " 'are',\n",
       " 'also',\n",
       " 'called',\n",
       " 'tints',\n",
       " 'and',\n",
       " 'shades',\n",
       " 'a',\n",
       " 'tint',\n",
       " 'being',\n",
       " 'a',\n",
       " 'green',\n",
       " 'or',\n",
       " 'other',\n",
       " 'hue',\n",
       " 'mixed',\n",
       " 'with',\n",
       " 'white',\n",
       " 'a',\n",
       " 'shade',\n",
       " 'being',\n",
       " 'mixed',\n",
       " 'with',\n",
       " 'black',\n",
       " 'A',\n",
       " 'large',\n",
       " 'selection',\n",
       " 'of',\n",
       " 'these',\n",
       " 'various',\n",
       " 'colors',\n",
       " 'is',\n",
       " 'shown',\n",
       " 'below']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'eating', 'cheetos']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I love eating cheetos\"\n",
    "sentence_token = word_tokenize(sentence)\n",
    "sentence_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('eating', 'VBG'), ('cheetos', 'NN')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(sentence_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'eating', 'mushroom', 'and', 'die', 'in', 'white', 'house']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2 = \"I eating mushroom and die in white house\"\n",
    "sentence_token2 = word_tokenize(sentence2)\n",
    "sentence_token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('eating', 'VBG'),\n",
       " ('mushroom', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('die', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('white', 'JJ'),\n",
       " ('house', 'NN')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_postag2 = pos_tag(sentence_token2)\n",
    "sentence_postag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m                     [\n\u001b[1;32m--> 798\u001b[1;33m                         find_binary(\n\u001b[0m\u001b[0;32m    799\u001b[0m                             \u001b[1;34m\"gs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    687\u001b[0m ):\n\u001b[1;32m--> 688\u001b[1;33m     return next(\n\u001b[0m\u001b[0;32m    689\u001b[0m         find_binary_iter(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m     for file in find_file_iter(\n\u001b[0m\u001b[0;32m    674\u001b[0m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"=\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n%s\\n%s\\n%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    815\u001b[0m                 )\n\u001b[0;32m    816\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('I', 'PRP'), ('eating', 'VBG'), ('mushroom', 'NN'), ('and', 'CC'), ('die', 'NN'), ('in', 'IN'), ('white', 'JJ'), ('house', 'NN')])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_ner = ne_chunk(sentence_postag2)\n",
    "ne_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
